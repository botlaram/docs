# AWS

## 3 Tier Application

![3tierappaws](./png/3tierapplicationaws.png)

# AWS

## Deploying a 3-Tier Application Architecture in AWS

![3tierappaws](./png/3tierapplicationaws.png)

This guide explains how to deploy a production-style 3-tier architecture in AWS with:

- Route 53
- ACM (SSL)
- VPC (Public & Private Subnets)
- Bastion Host
- RDS MySQL (Multi-AZ)
- Presentation Tier (Frontend)
- Application Tier (Backend)
- Auto Scaling
- CloudWatch Monitoring

---

### 3-Tier Architecture

1. **Presentation Tier**
   - Public ALB
   - EC2 instances (Frontend)

2. **Application Tier**
   - Internal ALB
   - EC2 instances (Backend - Node.js)

3. **Data Tier**
   - RDS MySQL (Multi-AZ)

---

#### 1Ô∏è‚É£ Create Route 53 Hosted Zone

Create Hosted Zone

- Domain Name: xyz.com
- Type:
  - Public Hosted Zone (Public Access)
  - Private Hosted Zone (VPC Only Access)

After creation:

- Copy assigned Name Servers (NS records)
- Go to external domain provider (e.g., GoDaddy)
- Replace existing nameservers with AWS NS values

---

#### 2Ô∏è‚É£ Request Public SSL Certificate (ACM)

Navigate to:

AWS Certificate Manager ‚Üí Request Certificate

Add domain names:

xyz.com  
xyz.in  

Choose:

DNS Validation

Create validation records in Route 53.

Wait until certificate status shows:

Issued

---

#### 3Ô∏è‚É£ Create VPC and Subnets

VPC Configuration

- Availability Zones: 2
- Public Subnets: 2
- Private Subnets: 4 (2 per AZ)
- NAT Gateway: 1 (single AZ)
- Endpoints: Not used

---

#### 4Ô∏è‚É£ Subnet Configuration

Enable for Public Subnets:

Auto-Assign Public IP ‚Üí Enabled

Private Subnets:

Auto-Assign Public IP ‚Üí Disabled

---

#### 5Ô∏è‚É£ Security Groups Configuration

Bastion Host SG

Inbound:
- SSH (22) ‚Üí Allow from specific IP (Production Best Practice)

---

##### Presentation Layer ALB SG

Inbound:
- HTTP (80) ‚Üí 0.0.0.0/0

Note: HTTPS can be configured later using CloudFront + ACM.

---

##### Presentation Layer EC2 SG

Inbound:
- SSH (22) ‚Üí Bastion SG
- HTTP (80) ‚Üí Presentation ALB SG

---

##### Application Layer ALB SG

Inbound:
- HTTP (80) ‚Üí Presentation EC2 SG

---

##### Application Layer EC2 SG

Inbound:
- SSH (22) ‚Üí Bastion SG
- TCP (3200) ‚Üí Application ALB SG

---

##### Data Tier SG

Inbound:
- MySQL (3306) ‚Üí Application EC2 SG
- MySQL (3306) ‚Üí Bastion SG

---

#### 6Ô∏è‚É£ Launch Bastion Host

EC2 ‚Üí Launch Instance

- AMI ‚Üí Amazon Linux
- Key Pair ‚Üí Create new
- VPC ‚Üí Public Subnet
- Security Group ‚Üí Bastion SG

---

#### 7Ô∏è‚É£ Create DB Subnet Group

RDS ‚Üí Subnet Groups ‚Üí Create

- Select VPC
- Select Private Subnets

---

#### 8Ô∏è‚É£ Create RDS MySQL (Multi-AZ)

RDS ‚Üí Create Database

- Engine ‚Üí MySQL
- Deployment ‚Üí Multi-AZ (Primary + Standby)
- Master Username
- Master Password
- Storage
- VPC
- DB Subnet Group
- Security Group ‚Üí Data Tier SG

---

#### 9Ô∏è‚É£ Connect to RDS

##### SSH to Bastion

```bash
ssh -i key.pem ec2-user@bastion-public-ip
```

##### Connect to MySQL

```bash
mysql -h <rds-endpoint> -u masteruser -p
```

##### Create App Database & User

```sql
CREATE DATABASE appdb;

CREATE USER 'appuser'@'%' IDENTIFIED BY 'password';

GRANT ALL PRIVILEGES ON appdb.* TO 'appuser'@'%';

FLUSH PRIVILEGES;
```

All application operations should use appuser.

---

#### üîü Setup Presentation Tier

##### Create Launch Template

- AMI
- Key Pair
- Public Subnet
- Presentation EC2 SG

##### User Data Script

```bash
#!/bin/bash
yum update -y
yum install nginx -y
systemctl start nginx
systemctl enable nginx

INSTANCE_ID=$(curl http://169.254.169.254/latest/meta-data/instance-id)
PUBLIC_IP=$(curl http://169.254.169.254/latest/meta-data/public-ipv4)

echo "Instance ID: $INSTANCE_ID" > /usr/share/nginx/html/index.html
echo "Public IP: $PUBLIC_IP" >> /usr/share/nginx/html/index.html
```

---

#### 1Ô∏è‚É£1Ô∏è‚É£ Create Presentation Target Group

- Target Type ‚Üí Instance
- Protocol ‚Üí HTTP
- Port ‚Üí 80
- VPC ‚Üí Select VPC
- Health Check ‚Üí /

---

#### 1Ô∏è‚É£2Ô∏è‚É£ Create Presentation Load Balancer (Internet Facing)

ALB Configuration:

- Scheme ‚Üí Internet Facing
- Subnets ‚Üí Public Subnets
- Security Group ‚Üí Presentation ALB SG
- Listener ‚Üí HTTP ‚Üí Forward to Presentation Target Group

---

#### 1Ô∏è‚É£3Ô∏è‚É£ Create Auto Scaling Group (Presentation Tier)

- Launch Template ‚Üí Presentation Template
- Subnets ‚Üí Public
- Attach ‚Üí Presentation Target Group
- Enable Health Check
- Enable CloudWatch
- Min Capacity ‚Üí 2
- Max Capacity ‚Üí 4
- Target CPU Utilization ‚Üí 50%

---

#### 1Ô∏è‚É£4Ô∏è‚É£ Test Auto Scaling

SSH to Presentation Instance:

```bash
sudo yum install stress -y
stress --cpu 2 --timeout 300
```

Monitor CloudWatch for scaling activity.

---

#### 1Ô∏è‚É£5Ô∏è‚É£ Setup Application Tier

##### Create Launch Template

- Instance Type ‚Üí t2.micro
- Private Subnet
- Application EC2 SG

##### User Data Script

```bash
#!/bin/bash
yum update -y
yum install git nodejs npm -y

git clone <repository-url>
cd app
npm install

cat <<EOF > .env
DB_HOST=<rds-endpoint>
DB_USER=appuser
DB_PASS=password
DB_NAME=appdb
EOF

npm start
```

---

#### 1Ô∏è‚É£6Ô∏è‚É£ Create Application Target Group

- Target Type ‚Üí Instance
- Protocol ‚Üí HTTP
- Port ‚Üí 3200
- VPC ‚Üí Select VPC
- Health Check ‚Üí /

---

#### 1Ô∏è‚É£7Ô∏è‚É£ Create Application Load Balancer (Internal)

- Scheme ‚Üí Internal
- Subnets ‚Üí Private Subnets
- Security Group ‚Üí Application ALB SG
- Listener ‚Üí HTTP ‚Üí Forward to Application Target Group

---

#### 1Ô∏è‚É£8Ô∏è‚É£ Create Auto Scaling Group (Application Tier)

- Launch Template ‚Üí Application Template
- Subnets ‚Üí Private
- Attach ‚Üí Application Target Group
- Enable Health Check
- Enable CloudWatch
- Min ‚Üí 2
- Max ‚Üí 4
- Target CPU ‚Üí 50%

---

#### 1Ô∏è‚É£9Ô∏è‚É£ Verify Application EC2

SSH:

Bastion ‚Üí Application EC2

Check logs:

```bash
cd app
cat logs/app.log
```

---

#### 2Ô∏è‚É£0Ô∏è‚É£ Update Presentation Tier (Frontend)

Create New Launch Template Version.

##### Updated User Data

```bash
#!/bin/bash
yum install git nodejs npm -y

git clone <frontend-repo>
cd frontend
npm install

cat <<EOF > .env
API_URL=http://<internal-application-alb>
DOMAIN=xyz.com
SUBDOMAIN=xyz.in
EOF

npm start
```

Update Launch Template Version in ASG.

---

##### 2Ô∏è‚É£1Ô∏è‚É£ Deploy Latest Version

Auto Scaling ‚Üí Presentation ASG

- Select Latest Launch Template Version
- Terminate Old Instances

Access:

http://xyz.com

---

#### 2Ô∏è‚É£2Ô∏è‚É£ Setup CloudWatch

##### Create IAM Role

- Attach Policy ‚Üí CloudWatchLogsFullAccess
- Attach Role ‚Üí EC2

---

#### 2Ô∏è‚É£3Ô∏è‚É£ Create Log Group

CloudWatch ‚Üí Log Groups ‚Üí Create

---

#### 2Ô∏è‚É£4Ô∏è‚É£ Install CloudWatch Agent

```bash
sudo yum install amazon-cloudwatch-agent -y
```

Attach IAM role to EC2 instance.

Configure CloudWatch agent.

---

#### 2Ô∏è‚É£5Ô∏è‚É£ View Logs

CloudWatch ‚Üí Log Groups

Monitor:

- Application logs
- System logs
- Metrics

---

#### ‚úÖ Final Architecture Flow

Route53  
   ‚Üì  
Public ALB  
   ‚Üì  
Presentation ASG (Public Subnets)  
   ‚Üì  
Internal ALB  
   ‚Üì  
Application ASG (Private Subnets)  
   ‚Üì  
RDS MySQL (Multi-AZ)  

---

#### üéØ Production Recommendations

- Enable HTTPS (ACM + ALB)
- Use AWS Secrets Manager for DB credentials
- Enable Automated RDS Backups
- Use WAF for security
- Consider CloudFront for CDN
- Implement Infrastructure as Code (Terraform)

---

üöÄ You now have a scalable, secure, production-ready 3-tier architecture in AWS.

## Scenario Based Questions

### Read and Write Separate Database (How to scale application to 1M users)

![aws1](./png/aws1.png)

Scaling AWS RDS with Read Replicas in EKS Architecture

I want to understand how database architecture works in AWS.
Suppose I have a web application hosted on AWS with an RDS database, and everything is functioning correctly.

In what scenarios should I use two separate databases ‚Äî one primary database for write operations and another read replica for read-only operations?

How does this architecture work internally, and how can it be implemented in AWS?

1Ô∏è‚É£ Current Scenario: Single RDS Instance

```bash
Users ‚Üí ALB ‚Üí EC2 / EKS ‚Üí RDS (Single DB)
```

All operations go to one database:

- `SELECT` (Read)
- `INSERT`
- `UPDATE`
- `DELETE`

This works perfectly when:

- Traffic is low to medium
- Read/write ratio is balanced
- Database CPU and connections are within limits

---

#### üö® 2Ô∏è‚É£ When Do You Need a Separate Write DB and Read Replica?

You introduce **Read Replicas** when scaling read operations becomes necessary.

---

üîπ Condition 1: Heavy Read Traffic

**Example:**

- E-commerce application
- 10,000 users browsing products (reads)
- 500 users placing orders (writes)
- Reads are 20x more than writes

Problem:

- Primary DB overloaded handling `SELECT` queries
- CPU spikes
- Slow queries
- Application performance degradation

üëâ **Solution:** Offload read traffic to replicas

---

üîπ Condition 2: Reporting & Analytics Queries

If:

- BI team runs large `SELECT` queries
- Long-running reporting jobs
- Heavy analytical workloads

These queries:

- Lock tables
- Consume CPU
- Impact production users

üëâ Run them on a **Read Replica**

---

üîπ Condition 3: Scaling Without Sharding

Instead of vertically scaling (larger DB instance),  
use horizontal scaling with read replicas ‚Äî often more cost-efficient.

---

#### üèó 3Ô∏è‚É£ Architecture with Read Replica

```bash
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Primary   ‚îÇ
                    ‚îÇ   (Write)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                    Replication
                          ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                   ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Read Replica‚îÇ      ‚îÇ Read Replica‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Application Flow

```bash
App Server
   ‚îÇ
   ‚îú‚îÄ‚îÄ Write ‚Üí Primary DB
   ‚îÇ
   ‚îî‚îÄ‚îÄ Read ‚Üí Read Replica
```

---

üîÅ 4Ô∏è‚É£ How Read Replica Works Internally

For MySQL / PostgreSQL:

- Asynchronous replication
- Binary logs (binlog)

#### Replication Flow

1. Client writes to Primary DB
2. Primary writes changes to binlog
3. Replica reads binlog
4. Replica applies changes

‚ö† **Important:**

- Replication is asynchronous
- Small delay (milliseconds to seconds)
- Called **replication lag**
- Provides *eventual consistency*, not strong consistency

---

#### üéØ When NOT to Use Read Replicas

‚ùå Write-heavy workloads  
‚ùå Applications requiring strict real-time consistency  
‚ùå Systems that cannot tolerate replication lag  

---

#### üÜö Multi-AZ vs Read Replica (Critical Difference)

üîπ Multi-AZ

- High Availability
- Standby DB
- Not used for reads
- Automatic failover

üîπ Read Replica

- Used for scaling reads
- Application connects to it
- No automatic failover (unless promoted)

---

‚öô 5Ô∏è‚É£ How to Implement Read Replica in AWS

Option 1: AWS Console

1. Go to RDS
2. Select your database
3. Click **Actions**
4. Choose **Create Read Replica**
5. Select instance size
6. Deploy

---

Option 2: AWS CLI

```bash
aws rds create-db-instance-read-replica \
    --db-instance-identifier mydb-replica \
    --source-db-instance-identifier mydb-primary \
    --db-instance-class db.t3.medium
```

---

Option 3: Terraform (Recommended for DevOps)

```hcl
resource "aws_db_instance" "primary" {
  identifier         = "mydb-primary"
  engine             = "mysql"
  instance_class     = "db.t3.medium"
  allocated_storage  = 20
  username           = "admin"
  password           = "password"
}

resource "aws_db_instance" "replica" {
  identifier          = "mydb-replica"
  replicate_source_db = aws_db_instance.primary.identifier
  instance_class      = "db.t3.medium"
}
```

---

üß† 6Ô∏è‚É£ Application-Level Implementation (Most Important)

AWS does **NOT** automatically split read/write traffic.

Your application must handle it.

### Example (Python Concept)

```python
write_db = connect(primary_endpoint)
read_db = connect(replica_endpoint)

# Write operation
write_db.execute("INSERT INTO users VALUES (...)")

# Read operation
read_db.execute("SELECT * FROM users")
```

---

## üè¢ Real-World Example

**Netflix-like workload:**

- Browse catalog ‚Üí Read
- Watch list ‚Üí Read
- Signup ‚Üí Write
- Like button ‚Üí Write

If 90% traffic is reads:

```bash
1 Primary
5 Read Replicas
```

---

## üìä Scaling Strategy

Start simple:

```bash
1 Primary
0 Replica
```

If CPU consistently > 70% due to reads:

```bash
1 Primary
1 Replica
```

As traffic increases:

```bash
1 Primary
3 Replicas
```
